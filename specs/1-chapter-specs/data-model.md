# Data Model & Flow: Physical AI & Humanoid Robotics Book\n\nThis document outlines the data models, message definitions, and data flow within the Physical AI & Humanoid Robotics project, emphasizing interoperability between components like ROS 2, simulation environments, and VLA systems.\n\n## 1. Core Data Entities & Schemas\n\n### 1.1 Robot State Data\n\n-   **Joint States:**\n    -   `sensor_msgs/JointState` (ROS 2 standard)\n    -   Fields: `header` (timestamp, frame\_id), `name` (string[]), `position` (float64[]), `velocity` (float64[]), `effort` (float64[])\n-   **Odometry:**\n    -   `nav_msgs/Odometry` (ROS 2 standard)\n    -   Fields: `header`, `child_frame_id`, `pose` (geometry\_msgs/PoseWithCovariance), `twist` (geometry\_msgs/TwistWithCovariance)\n-   **TF (Transform Frames):**\n    -   `tf2_msgs/TFMessage` (ROS 2 standard)\n    -   Fields: `transforms` (geometry\_msgs/TransformStamped[])\n\n### 1.2 Perception Data\n\n-   **Camera Images:**\n    -   `sensor_msgs/Image` (ROS 2 standard)\n    -   Fields: `header`, `height`, `width`, `encoding`, `is_bigendian`, `step`, `data` (uint8[])\n-   **Depth Images:**\n    -   `sensor_msgs/Image` (ROS 2 standard, typically `32FC1` or `16UC1` encoding)\n-   **Point Clouds:**\n    -   `sensor_msgs/PointCloud2` (ROS 2 standard)\n    -   Fields: `header`, `height`, `width`, `fields` (PointField[]), `is_bigendian`, `point_step`, `row_step`, `data` (uint8[]), `is_dense`\n-   **Object Detections:**\n    -   Custom ROS 2 message (e.g., `ai_perception_msgs/Detection2DArray`)\n    -   Fields: `header`, `detections` (Detection2D[])\n    -   `Detection2D`: `bbox` (perception_msgs/BoundingBox2D), `label` (string), `score` (float64), `id` (int32)\n-   **Pose Estimates:**\n    -   `geometry_msgs/PoseStamped` or custom message (e.g., `ai_perception_msgs/ObjectPoseArray`)\n\n### 1.3 Navigation Data\n\n-   **Global Map:**\n    -   `nav_msgs/OccupancyGrid` (ROS 2 standard)\n    -   Fields: `header`, `info` (MapMetaData), `data` (int8[])\n-   **Path:**\n    -   `nav_msgs/Path` (ROS 2 standard)\n    -   Fields: `header`, `poses` (geometry\_msgs/PoseStamped[])\n-   **Goal Poses:**\n    -   `geometry_msgs/PoseStamped` (ROS 2 standard)\n\n### 1.4 VLA (Vision-Language-Action) Data\n\n-   **Voice Input:**\n    -   `std_msgs/String` (ROS 2 for transcribed text)\n    -   Audio stream (internal to Whisper, not typically exposed as ROS message for raw audio)\n-   **LLM Commands/Plans:**\n    -   Custom ROS 2 message (e.g., `vla_msgs/LLMPlan`)\n    -   Fields: `header`, `command_text` (string), `action_sequence` (Action[]), `context` (string)\n    -   `Action`: `type` (string), `parameters` (string[])\n-   **Multi-modal Features:**\n    -   Combination of perception data (images, point clouds) and text descriptions (extracted features, captions).\n\n## 2. Data Flow Diagrams (Conceptual)\n\n### 2.1 Simulation Pipeline (Gazebo ↔ ROS 2 ↔ Unity)\n\n```mermaid\ngraph TD\n    Gazebo((Gazebo Sim)) -->|Physics, Joint States, Sensor Data| ROS2[ROS 2 Nodes]\n    ROS2 -->|Commands, TF| Gazebo\n    ROS2 -->|Robot State, Perception Data| Unity((Unity Visualization))\n    Unity -->|High-Level Commands| ROS2\n```\n\n### 2.2 VLA Pipeline (Voice, LLM, Perception, Control)\n\n```mermaid\ngraph TD\n    VoiceInput(Voice Input - Whisper) -->|Transcribed Text| LLM((LLM Cognitive Planning))\n    LLM -->|High-Level Actions| ActionExecutor[ROS 2 Action Executor]\n    Perception[Isaac ROS Perception] -->|Object Detections, Poses| LLM\n    ActionExecutor -->|Low-Level Control Commands| ROS2Control(ROS 2 Control Layers)\n    ROS2Control -->|Joint Commands| Robot((Humanoid Robot))\n    Robot -->|Joint States, Sensor Feedback| Perception\n```\n\n## 3. ROS 2 Message Definitions & Topics\n\nCommon ROS 2 topics and message types used for interoperability:\n\n-   `/joint_states`: `sensor_msgs/JointState`\n-   `/odom`: `nav_msgs/Odometry`\n-   `/tf`, `/tf_static`: `tf2_msgs/TFMessage`\n-   `/camera/image_raw`: `sensor_msgs/Image`\n-   `/depth/image_raw`: `sensor_msgs/Image`\n-   `/points`: `sensor_msgs/PointCloud2`\n-   `/map`: `nav_msgs/OccupancyGrid`\n-   `/global_plan`: `nav_msgs/Path`\n-   `/goal_pose`: `geometry_msgs/PoseStamped`\n-   `/vla/transcribed_text`: `std_msgs/String`\n-   `/vla/llm_plan`: `vla_msgs/LLMPlan` (custom)\n\n## 4. Storage Formats\n\n-   **Configuration:** YAML for ROS 2 parameters, URDF/Xacro for robot descriptions.\n-   **Sensor Data Logging:** ROS bags (`.db3` format) for recording and playback of all ROS 2 topics.\n-   **Model Checkpoints:** ONNX, OpenVINO, or PyTorch/TensorFlow native formats for AI models.\n-   **Documentation Assets:** PNG/JPG for diagrams and images, Markdown/MDX for text.\n\n## 5. Architectural Decisions Affecting Data\n\n-   **ROS 2 Version:** Humble Hawksbill or Iron Irongrip (chosen for long-term support and stability).\n    -   *Impact:* Dictates available message types, middleware features (DDS implementation), and client libraries.\n-   **`rclpy` vs `rclcpp`:** Python (`rclpy`) for high-level VLA and rapid prototyping; C++ (`rclcpp`) for performance-critical perception and control loops.\n    -   *Impact:* Affects data serialization/deserialization overhead and memory management for messages between nodes.\n-   **URDF vs Xacro:** Xacro preferred for modularity and parameterized robot descriptions.\n    -   *Impact:* Influences how robot parameters are defined and passed into simulation/control layers.\n-   **Simulator Choice:** NVIDIA Isaac Sim for primary development due to GPU acceleration, physics accuracy, and integrated ROS support. Gazebo for comparative study and broader community context.\n    -   *Impact:* Affects sensor fidelity, physics engine properties, and the need for specific bridge mechanisms for data exchange.\n-   **ASR Model:** OpenAI Whisper for its robust performance and ease of integration.\n    -   *Impact:* Determines output text format, latency, and accuracy of voice command transcription.\n-   **Deployment Modality:** Jetson Orin for on-robot deployment; containerization (Docker, NVIDIA Container Toolkit) for consistent environments.\n    -   *Impact:* Defines data transfer mechanisms to/from edge device, potential for custom message serialization for bandwidth optimization.\n