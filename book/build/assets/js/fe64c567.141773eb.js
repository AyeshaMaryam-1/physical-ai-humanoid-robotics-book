"use strict";(globalThis.webpackChunkbook_temp=globalThis.webpackChunkbook_temp||[]).push([[759],{8453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>a});var o=t(6540);const i={},r=o.createContext(i);function s(n){const e=o.useContext(r);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),o.createElement(r.Provider,{value:e},n.children)}},9486:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module_1/1_4_ai_controllers","title":"Connecting AI Agents to ROS Controllers","description":"Purpose","source":"@site/docs/01_module_1/1_4_ai_controllers.mdx","sourceDirName":"01_module_1","slug":"/module_1/1_4_ai_controllers","permalink":"/physical-ai-humanoid-robotics-book/docs/module_1/1_4_ai_controllers","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/01_module_1/1_4_ai_controllers.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Connecting AI Agents to ROS Controllers"},"sidebar":"tutorialSidebar","previous":{"title":"Robot Description (URDF for Humanoids)","permalink":"/physical-ai-humanoid-robotics-book/docs/module_1/1_3_urdf"},"next":{"title":"Simulation Fundamentals in Gazebo","permalink":"/physical-ai-humanoid-robotics-book/docs/module_2/2_1_gazebo_fundamentals"}}');var i=t(4848),r=t(8453);const s={sidebar_position:4,title:"Connecting AI Agents to ROS Controllers"},a="Connecting AI Agents to ROS Controllers",l={},c=[{value:"Purpose",id:"purpose",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Inputs",id:"inputs",level:2},{value:"Outputs",id:"outputs",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Chapter Outline",id:"chapter-outline",level:2},{value:"1. AI-ROS Communication Patterns",id:"1-ai-ros-communication-patterns",level:3},{value:"2. AI Agent Design for Robotics",id:"2-ai-agent-design-for-robotics",level:3},{value:"3. Controller Integration",id:"3-controller-integration",level:3},{value:"4. Safety and Validation",id:"4-safety-and-validation",level:3},{value:"Hands-On Lab",id:"hands-on-lab",level:2},{value:"Creating an AI Control Agent",id:"creating-an-ai-control-agent",level:3},{value:"Safety Notes",id:"safety-notes",level:2},{value:"Evaluation Criteria",id:"evaluation-criteria",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"connecting-ai-agents-to-ros-controllers",children:"Connecting AI Agents to ROS Controllers"})}),"\n",(0,i.jsx)(e.h2,{id:"purpose",children:"Purpose"}),"\n",(0,i.jsx)(e.p,{children:"This chapter explores the integration of AI agents with ROS 2 controllers, bridging the gap between high-level AI decision-making and low-level robot control. It covers the design patterns and implementation strategies for connecting intelligent systems to robotic control frameworks."}),"\n",(0,i.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(e.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Design interfaces between AI agents and ROS 2 controllers"}),"\n",(0,i.jsx)(e.li,{children:"Implement AI decision-making nodes that interact with robot controllers"}),"\n",(0,i.jsx)(e.li,{children:"Create feedback loops between AI agents and robot sensors"}),"\n",(0,i.jsx)(e.li,{children:"Integrate AI planning with ROS 2 action servers"}),"\n",(0,i.jsx)(e.li,{children:"Implement safety mechanisms for AI-driven robot control"}),"\n",(0,i.jsx)(e.li,{children:"Evaluate the performance of AI-ROS integration systems"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Understanding of ROS 2 concepts and node communication"}),"\n",(0,i.jsx)(e.li,{children:"Knowledge of basic AI/ML concepts"}),"\n",(0,i.jsx)(e.li,{children:"Completed previous chapters on ROS 2 and URDF"}),"\n",(0,i.jsx)(e.li,{children:"Working knowledge of Python programming"}),"\n",(0,i.jsx)(e.li,{children:"Understanding of robot control concepts"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"inputs",children:"Inputs"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Working ROS 2 installation (Humble Hawksbill or later)"}),"\n",(0,i.jsx)(e.li,{children:"Understanding of AI/ML concepts"}),"\n",(0,i.jsx)(e.li,{children:"Completed humanoid robot URDF model"}),"\n",(0,i.jsx)(e.li,{children:"Knowledge of robot control systems"}),"\n",(0,i.jsx)(e.li,{children:"Python programming skills"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"outputs",children:"Outputs"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"AI agent that can command a simulated robot"}),"\n",(0,i.jsx)(e.li,{children:"Integration between AI decision-making and ROS 2 controllers"}),"\n",(0,i.jsx)(e.li,{children:"Working example of AI-ROS communication"}),"\n",(0,i.jsx)(e.li,{children:"Safety mechanisms for AI-driven control"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"AI-ROS Integration"}),": Connecting artificial intelligence systems with robot control frameworks"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Action Servers"}),": Long-running tasks with feedback and goal management in ROS 2"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Behavior Trees"}),": Hierarchical task planning for complex robot behaviors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"State Machines"}),": Managing robot states and transitions in AI systems"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Feedback Control"}),": Closing the loop between AI decisions and robot execution"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Safety Boundaries"}),": Ensuring AI decisions don't compromise robot safety"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Simulation Integration"}),": Testing AI-ROS integration in simulated environments"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"chapter-outline",children:"Chapter Outline"}),"\n",(0,i.jsx)(e.p,{children:"This chapter covers the integration of AI with robot control systems:"}),"\n",(0,i.jsx)(e.h3,{id:"1-ai-ros-communication-patterns",children:"1. AI-ROS Communication Patterns"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Publisher-subscriber for sensor data"}),"\n",(0,i.jsx)(e.li,{children:"Service calls for discrete actions"}),"\n",(0,i.jsx)(e.li,{children:"Action servers for complex tasks"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"2-ai-agent-design-for-robotics",children:"2. AI Agent Design for Robotics"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Perception-processing-action cycles"}),"\n",(0,i.jsx)(e.li,{children:"State representation for robots"}),"\n",(0,i.jsx)(e.li,{children:"Decision-making under uncertainty"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"3-controller-integration",children:"3. Controller Integration"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Joint trajectory controllers"}),"\n",(0,i.jsx)(e.li,{children:"Cartesian position controllers"}),"\n",(0,i.jsx)(e.li,{children:"Force/torque control interfaces"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"4-safety-and-validation",children:"4. Safety and Validation"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Safety constraints for AI decisions"}),"\n",(0,i.jsx)(e.li,{children:"Validation of AI-generated commands"}),"\n",(0,i.jsx)(e.li,{children:"Emergency stop mechanisms"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"hands-on-lab",children:"Hands-On Lab"}),"\n",(0,i.jsx)(e.h3,{id:"creating-an-ai-control-agent",children:"Creating an AI Control Agent"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Navigate to your ROS 2 workspace and create the ai_control_agent package:"}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"cd ~/robotics_ws/src\nros2 pkg create --build-type ament_python ai_control_agent\n"})}),"\n",(0,i.jsxs)(e.ol,{start:"2",children:["\n",(0,i.jsxs)(e.li,{children:["Create the AI control agent node in ",(0,i.jsx)(e.code,{children:"ai_control_agent/ai_control_agent/simple_ai_agent.py"}),":"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import JointState\nfrom control_msgs.msg import JointTrajectoryControllerState\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\nfrom builtin_interfaces.msg import Duration\nimport random\nimport math\n\n\nclass SimpleAIAgentNode(Node):\n    def __init__(self):\n        super().__init__('simple_ai_agent')\n\n        # Publisher for joint trajectory commands\n        self.joint_cmd_publisher = self.create_publisher(\n            JointTrajectory,\n            '/joint_trajectory_controller/joint_trajectory',\n            10\n        )\n\n        # Subscriber for joint states\n        self.joint_state_subscriber = self.create_subscription(\n            JointState,\n            '/joint_states',\n            self.joint_state_callback,\n            10\n        )\n\n        # Subscriber for obstacle alerts\n        self.obstacle_subscriber = self.create_subscription(\n            String,\n            'obstacle_alert',\n            self.obstacle_callback,\n            10\n        )\n\n        # Timer for AI decision making\n        timer_period = 2.0  # seconds\n        self.timer = self.create_timer(timer_period, self.ai_decision_callback)\n\n        # Robot state tracking\n        self.current_joint_positions = {}\n        self.obstacle_detected = False\n\n        # Define joint names for the simple humanoid (from URDF)\n        self.joint_names = [\n            'left_shoulder', 'left_elbow', 'right_shoulder', 'right_elbow',\n            'left_hip', 'left_knee', 'right_hip', 'right_knee'\n        ]\n\n        self.get_logger().info('Simple AI Agent Node initialized')\n\n    def joint_state_callback(self, msg):\n        \"\"\"Update current joint positions from joint state messages\"\"\"\n        for i, name in enumerate(msg.name):\n            if name in self.joint_names:\n                self.current_joint_positions[name] = msg.position[i]\n\n    def obstacle_callback(self, msg):\n        \"\"\"Handle obstacle detection messages\"\"\"\n        self.obstacle_detected = True\n        self.get_logger().warn(f'Obstacle detected: {msg.data}')\n\n        # Implement obstacle avoidance behavior\n        self.execute_avoidance_behavior()\n\n    def ai_decision_callback(self):\n        \"\"\"Main AI decision-making loop\"\"\"\n        if self.obstacle_detected:\n            self.get_logger().info('Avoiding obstacle')\n            return\n\n        # Simple AI behavior: move joints to random positions\n        self.execute_random_movement()\n\n    def execute_random_movement(self):\n        \"\"\"Execute random joint movements\"\"\"\n        trajectory_msg = JointTrajectory()\n        trajectory_msg.joint_names = self.joint_names\n\n        point = JointTrajectoryPoint()\n\n        # Generate random positions for each joint within limits\n        for joint_name in self.joint_names:\n            # Generate random position between -1.0 and 1.0 radians\n            random_position = random.uniform(-1.0, 1.0)\n            point.positions.append(random_position)\n\n            # Set velocity and acceleration to 0 for simplicity\n            point.velocities.append(0.0)\n            point.accelerations.append(0.0)\n\n        # Set the time from start (2 seconds)\n        point.time_from_start = Duration(sec=2, nanosec=0)\n        trajectory_msg.points = [point]\n\n        self.joint_cmd_publisher.publish(trajectory_msg)\n        self.get_logger().info(f'AI commanded joint positions: {[round(p, 2) for p in point.positions]}')\n\n    def execute_avoidance_behavior(self):\n        \"\"\"Execute obstacle avoidance behavior\"\"\"\n        trajectory_msg = JointTrajectory()\n        trajectory_msg.joint_names = self.joint_names\n\n        point = JointTrajectoryPoint()\n\n        # For obstacle avoidance, move to a \"safe\" position\n        # In a real implementation, this would be more sophisticated\n        for joint_name in self.joint_names:\n            # Move to neutral position (0.0) for all joints\n            point.positions.append(0.0)\n            point.velocities.append(0.0)\n            point.accelerations.append(0.0)\n\n        # Set the time from start (1 second for quick response)\n        point.time_from_start = Duration(sec=1, nanosec=0)\n        trajectory_msg.points = [point]\n\n        self.joint_cmd_publisher.publish(trajectory_msg)\n        self.get_logger().info('AI executed obstacle avoidance behavior')\n\n        # Reset obstacle flag after a short delay\n        self.create_timer(1.0, self.reset_obstacle_flag)\n\n    def reset_obstacle_flag(self):\n        \"\"\"Reset the obstacle detection flag\"\"\"\n        self.obstacle_detected = False\n        self.get_logger().info('Obstacle flag reset')\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SimpleAIAgentNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsxs)(e.ol,{start:"3",children:["\n",(0,i.jsxs)(e.li,{children:["Update the ",(0,i.jsx)(e.code,{children:"setup.py"})," file in ",(0,i.jsx)(e.code,{children:"ai_control_agent/setup.py"}),":"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import os\nfrom glob import glob\nfrom setuptools import setup\nfrom setuptools import find_packages\n\npackage_name = 'ai_control_agent'\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='Humanoid Robotics Book',\n    maintainer_email='humanoid-robotics-book@example.com',\n    description='AI control agent for the Physical AI & Humanoid Robotics book',\n    license='Apache License 2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'simple_ai_agent = ai_control_agent.simple_ai_agent:main',\n        ],\n    },\n)\n"})}),"\n",(0,i.jsxs)(e.ol,{start:"4",children:["\n",(0,i.jsxs)(e.li,{children:["Create the package.xml file in ",(0,i.jsx)(e.code,{children:"ai_control_agent/package.xml"}),":"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\n<package format="3">\n  <name>ai_control_agent</name>\n  <version>0.0.0</version>\n  <description>AI control agent for the Physical AI & Humanoid Robotics book</description>\n  <maintainer email="humanoid-robotics-book@example.com">Humanoid Robotics Book</maintainer>\n  <license>Apache-2.0</license>\n\n  <depend>rclpy</depend>\n  <depend>std_msgs</depend>\n  <depend>sensor_msgs</depend>\n  <depend>control_msgs</depend>\n  <depend>trajectory_msgs</depend>\n  <depend>builtin_interfaces</depend>\n\n  <exec_depend>python3-numpy</exec_depend>\n\n  <test_depend>ament_copyright</test_depend>\n  <test_depend>ament_flake8</test_depend>\n  <test_depend>ament_pep257</test_depend>\n  <test_depend>python3-pytest</test_depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>\n'})}),"\n",(0,i.jsxs)(e.ol,{start:"5",children:["\n",(0,i.jsx)(e.li,{children:"Create a launch file to integrate the AI agent with ros2_control:"}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"mkdir -p ~/robotics_ws/src/ai_control_agent/launch\n"})}),"\n",(0,i.jsxs)(e.ol,{start:"6",children:["\n",(0,i.jsxs)(e.li,{children:["Create the launch file at ",(0,i.jsx)(e.code,{children:"ai_control_agent/launch/ai_agent_control.launch.py"}),":"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, RegisterEventHandler\nfrom launch.substitutions import LaunchConfiguration\nfrom launch_ros.actions import Node\nfrom launch.substitutions import Command, PathJoinSubstitution\nfrom launch_ros.substitutions import FindPackageShare\nfrom ament_index_python.packages import get_package_share_directory\nfrom launch.event_handlers import OnProcessExit\nimport os\n\n\ndef generate_launch_description():\n    # Get the package share directory\n    pkg_share = get_package_share_directory('humanoid_description')\n\n    # Define the URDF file path\n    default_model_path = os.path.join(pkg_share, 'urdf/simple_humanoid.urdf')\n\n    # Declare launch arguments\n    model_arg = DeclareLaunchArgument(\n        name='model',\n        default_value=default_model_path,\n        description='Absolute path to robot urdf file'\n    )\n\n    # Robot State Publisher node\n    robot_state_publisher_node = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        parameters=[{\n            'robot_description': Command(['xacro ', LaunchConfiguration('model')])\n        }]\n    )\n\n    # ros2_control Node\n    ros2_controllers_path = os.path.join(\n        get_package_share_directory('ai_control_agent'),\n        'config',\n        'controllers.yaml'\n    )\n\n    # Create controllers.yaml configuration file\n    controllers_config = \"\"\"\n    controller_manager:\n      ros__parameters:\n        update_rate: 100  # Hz\n\n        joint_state_broadcaster:\n          type: joint_state_broadcaster/JointStateBroadcaster\n\n        joint_trajectory_controller:\n          type: joint_trajectory_controller/JointTrajectoryController\n    \"\"\"\n\n    # Write controllers.yaml to the config directory\n    config_dir = os.path.join(get_package_share_directory('ai_control_agent'), 'config')\n    os.makedirs(config_dir, exist_ok=True)\n    controllers_file = os.path.join(config_dir, 'controllers.yaml')\n    with open(controllers_file, 'w') as f:\n        f.write(controllers_config)\n\n    controller_manager_node = Node(\n        package='controller_manager',\n        executable='ros2_control_node',\n        parameters=[controllers_file],\n        remappings=[\n            ('~/robot_description', '/robot_description'),\n        ],\n        output='both',\n    )\n\n    # Joint State Broadcaster\n    joint_state_broadcaster_spawner = Node(\n        package='controller_manager',\n        executable='spawner',\n        arguments=['joint_state_broadcaster'],\n    )\n\n    # Joint Trajectory Controller\n    joint_trajectory_controller_spawner = Node(\n        package='controller_manager',\n        executable='spawner',\n        arguments=['joint_trajectory_controller'],\n    )\n\n    # Simple AI Agent node\n    ai_agent_node = Node(\n        package='ai_control_agent',\n        executable='simple_ai_agent',\n        name='simple_ai_agent',\n        output='screen'\n    )\n\n    # RViz2 node\n    rviz_config_file = PathJoinSubstitution(\n        [FindPackageShare('humanoid_description'), 'rviz', 'display.rviz']\n    )\n\n    rviz_node = Node(\n        package='rviz2',\n        executable='rviz2',\n        name='rviz2',\n        # arguments=['-d', rviz_config_file],\n        output='screen'\n    )\n\n    # Delay rviz start after joint_state_broadcaster spawner finishes\n    delay_rviz_after_joint_state_broadcaster_spawner = RegisterEventHandler(\n        event_handler=OnProcessExit(\n            target_action=joint_state_broadcaster_spawner,\n            on_exit=[rviz_node],\n        )\n    )\n\n    return LaunchDescription([\n        model_arg,\n        robot_state_publisher_node,\n        controller_manager_node,\n        joint_state_broadcaster_spawner,\n        joint_trajectory_controller_spawner,\n        ai_agent_node,\n        delay_rviz_after_joint_state_broadcaster_spawner\n    ])\n"})}),"\n",(0,i.jsxs)(e.ol,{start:"7",children:["\n",(0,i.jsx)(e.li,{children:"Build the package:"}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"cd ~/robotics_ws\ncolcon build --packages-select ai_control_agent\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(e.h2,{id:"safety-notes",children:"Safety Notes"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Always implement safety limits and bounds checking in AI agents"}),"\n",(0,i.jsx)(e.li,{children:"Include emergency stop mechanisms in all AI-driven control systems"}),"\n",(0,i.jsx)(e.li,{children:"Test AI-ROS integration thoroughly in simulation before real robot deployment"}),"\n",(0,i.jsx)(e.li,{children:"Implement proper error handling and recovery strategies"}),"\n",(0,i.jsx)(e.li,{children:"Monitor AI agent behavior during execution and implement intervention mechanisms"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"evaluation-criteria",children:"Evaluation Criteria"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Can the AI agent successfully command robot joints?"}),"\n",(0,i.jsx)(e.li,{children:"Is there proper feedback from robot sensors to the AI agent?"}),"\n",(0,i.jsx)(e.li,{children:"Are safety mechanisms properly implemented?"}),"\n",(0,i.jsx)(e.li,{children:"Can the AI agent adapt its behavior based on sensor feedback?"}),"\n",(0,i.jsx)(e.li,{children:"Is the integration between AI and ROS 2 controllers functional and reliable?"}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}}}]);